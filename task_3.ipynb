{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для кращого аналізу моделі регресії дані з файлу internship_train.csv потрібно поділити на дві частини: 80%(train) та 20%(test). Перша частину даних буде використовуватися для побудови моделі регресії. Друга -- для перевірки точності даної моделі."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так як internship_train.csv складається з рядків і стовбчиків, то потрібно дізнатися скільки рядків займає 80%.\n",
    "train_len -- це кількість 80% рядків з документа internship_train.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "result = pd.read_csv('internship_train.csv')\n",
    "train_len = int(len(result)*0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X_train, y_train -- вибірка для тренування моделі\n",
    "X_test, y_test -- вибірка для тeстування моделі"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(\"internship_train.csv\")\n",
    "X_train = data_file.iloc[:train_len + 1, 0:53].values\n",
    "y_train = data_file.iloc[: train_len + 1, -1:].values\n",
    "X_test = data_file.iloc [train_len + 1 : , 0:53].values\n",
    "y_test = data_file.iloc[train_len + 1:, -1:].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Було розглянуто лінійні регресії з пакетів sklearn (LinearRegression, Ridge, Lasso) та statsmodels (OLS). Та додатково вирішила розглянути регресію, яка використовує дерево рішень з пакету sklearn.tree (DecisionTreeRegressor)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Перша модель, яка використовується -- LinearRegression з пакету sklearn.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for train data: 28.87553729562131\n",
      "R^2  for train: 0.0007971217742648307\n",
      "RMSE for test data: 28.948200951350213\n",
      "R^2 fo test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "#використовуємо модель на тренувальних даних\n",
    "model_LR = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "#розраховуємо передбачувані для тренувальних даних\n",
    "y_train_pred = model_LR.predict(X_train)\n",
    "\n",
    "#розраховуємо коефіцієнт детермінації R^2 для тренувальних даних та серднє квадратичне відхилення RMSE для передбачуваних даних, які розрахувала дана модель  і спражніми даними\n",
    "r2_train = model_LR.score(X_train, y_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(f'RMSE for train data: {rmse_train}')\n",
    "print(f'R^2  for train: {r2_train}')\n",
    "\n",
    "#Використовуємо нашу модель на даних, які не проходили тренування. І анлогічно розраховуємо коефіцієнт детермінації R^2 та серднє квадратичне відхилення RMSE\n",
    "y_test_pred = model_LR.predict(X_test)\n",
    "r2_test = model_LR.score(X_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "#\n",
    "print(f'RMSE for test data: {rmse_test}')\n",
    "print(f'R^2 fo test data: {r2_test}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "З результатів видно, що R^2 дорівнює 1. Це означає, що дана модель точно передбачає тестові дані.\n",
    "\n",
    "RMSE for train data: 28.87553729562131\n",
    "R^2  for train: 0.0007971217742648307\n",
    "RMSE for test data: 28.948200951350213\n",
    "R^2 fo test data: 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Розглянемо модель Ridge. Це алгоритм регуляризації лінійної регресії зменшує, що коеф. регресії та запобігає перенавчання моделі.\n",
    "alpha -- параметр, що контролює силу регуляризації регресії.\n",
    "Як і з моделлю LinearRegression повторюємо аналогічні розрахунки для R^2 та RMSE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE тренувальної вибірки: 28.875537295621317\n",
      "R^2 тренувальної вибірки: 0.0007971217742641645\n",
      "RMSE тестової вибірки: 28.9482009416222\n",
      "R^2 тестової вибірки: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_R = Ridge(alpha=0.01).fit(X_train, y_train)\n",
    "y_train_pred = model_R.predict(X_train)\n",
    "r2_train = model_R.score(X_train, y_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(f'RMSE тренувальної вибірки: {rmse_train}')\n",
    "print(f'R^2 тренувальної вибірки: {r2_train}')\n",
    "\n",
    "y_test_pred = model_R.predict(X_test)\n",
    "r2_test = model_R.score(X_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f'RMSE тестової вибірки: {rmse_test}')\n",
    "print(f'R^2 тестової вибірки: {r2_test}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можна помітити, що коф R^2 та RMSE майже однакові і відрізняються тільки в п'ятому знаку після крапки. Тому можна вважати, що ці дві моделі ідентичні."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lasso -- також є алгоритмом регуляризації лінійної регресії тільки по їншому параметру ніж Ridge.\n",
    "alpha -- параметр, що контролює силу регуляризації регресії.\n",
    "Повторюємо аналогічні розрахунки"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE тренувальної вибірки: 28.878046226957874\n",
      "R^2 тренувальної вибірки: 0.0006234771907577263\n",
      "RMSE тестової вибірки: 28.944605776831075\n",
      "R^2 тестової вибірки: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_L = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "y_train_pred = model_L.predict(X_train)\n",
    "r2_train = model_L.score(X_train, y_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(f'RMSE тренувальної вибірки: {rmse_train}')\n",
    "print(f'R^2 тренувальної вибірки: {r2_train}')\n",
    "\n",
    "y_test_pred = model_L.predict(X_test)\n",
    "r2_test = model_L.score(X_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "#\n",
    "print(f'RMSE тестової вибірки: {rmse_test}')\n",
    "print(f'R^2 тестової вибірки: {r2_test}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Також параметр RMSE відрізняється лише в третьому знаку після крапки, тому цей метод сильних покращень нв цей параметр не вніс."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "OLS -- це алгоритм лінійної регресії в пакеті statmodels, що реалізується за допомоги методу найменших квадратів."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE тренувальної вибірки: 29.126346410053948\n",
      "R^2 тренувальної вибірки: 0.7460365214209876\n",
      "RMSE тренувальної вибірки: 29.24198460761056\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(X_train)\n",
    "model_OLS = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "y_train_pred = model_OLS.predict(X_train)\n",
    "\n",
    "r2_train = model_OLS.rsquared\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "print(f'RMSE тренувальної вибірки: {rmse_train}')\n",
    "print(f'R^2 тренувальної вибірки: {r2_train}')\n",
    "\n",
    "y_test_pred = model_OLS.predict(X_test)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(f'RMSE тренувальної вибірки: {rmse_test}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Фле порівнюючи лінійні регресії з пакета sklearn і даний метод з пакета statmodels, можна зробити висновок, що попередні алгоритми працювали краще, бо RMSE було менше"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Останній алгоритм це DecisionTreeRegressor. Він використовує деревоподібну структуру для побудови моделі регресії, яка може передбачати числові значення вихідної змінної."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE тренувальної вибірки: 1.8501688274686544e-08\n",
      "R^2 тренувальної вибірки: 1.0\n",
      "RMSE тестової вибірки: 0.007675642392300156\n",
      "R^2 тестової вибірки: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_DTR = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "y_train_pred = model_DTR.predict(X_train)\n",
    "r2_train = model_DTR.score(X_train, y_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(f'RMSE тренувальної вибірки: {rmse_train}')\n",
    "print(f'R^2 тренувальної вибірки: {r2_train}')\n",
    "\n",
    "y_test_pred = model_DTR.predict(X_test)\n",
    "r2_test = model_DTR.score(X_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "#\n",
    "print(f'RMSE тестової вибірки: {rmse_test}')\n",
    "print(f'R^2 тестової вибірки: {r2_test}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Як можна бачити, що RMSE за допомогою моделі DecisionTreeRegressor зменшився до 0.0077. При умові що R^2 = 1. Тобто дана модель точно передбачає тестові дані.\n",
    "Тому я вважаю, що краще буде використовувати як модель цей алгоритм регресії."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}